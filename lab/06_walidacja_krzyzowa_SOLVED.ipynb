{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move to utils\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_data(split=True):\n",
    "    \n",
    "    data = load_breast_cancer()\n",
    "\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    \n",
    "    if split:\n",
    "        return train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1.1\n",
    "\n",
    "Używając modelu [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) z pakietu sklearn uzyskać 100% dokładność (mierzoną miarą [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html))na zbiorze treningowym. Państwa zadanie polega na dobraniu paramtru `gamma`, dla ułatwienia proszę nie zmieniać pozotsałych domyślnych paramertów. Zalecany przedział parametru `gamma` to wartości z przedziału [0, 1] w skali logarytmicznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.033333\ttrain: 1.000\n",
      "Gamma: 0.000001\ttrain: 0.911\n",
      "Gamma: 0.000010\ttrain: 0.915\n",
      "Gamma: 0.000100\ttrain: 0.941\n",
      "Gamma: 0.001000\ttrain: 0.977\n",
      "Gamma: 0.010000\ttrain: 1.000\n",
      "Gamma: 0.100000\ttrain: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# your code here\n",
    "\n",
    "auto_gamma = 1 / X_train.shape[1]\n",
    "scale_gamma = 1 / (X_train.shape[1] * X_train.var())\n",
    "\n",
    "best_train_acc = 0\n",
    "\n",
    "for g in [auto_gamma, scale_gamma, 0.00001, 0.0001, 0.001, 0.01, 0.1]:\n",
    "\n",
    "    svm = SVC(C=1, gamma=g)\n",
    "\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = svm.score(X_train, y_train)\n",
    "    \n",
    "    if train_score > best_train_acc:\n",
    "        best_gamma = g\n",
    "        best_train_acc = train_score\n",
    "    \n",
    "    print(f\"Gamma: {g:0.6f}\", end='\\t')\n",
    "    print(f\"train: {train_score:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "best_gamma = best_gamma # ???\n",
    "\n",
    "svm = SVC(gamma=best_gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "train_acc = svm.score(X_train, y_train)\n",
    "\n",
    "assert train_acc == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1.2\n",
    "Używając tej samej rodziny modeli znajdź tym razem taką wartośc `gamma`, która daje najlepszy wynik na zbiorze **testowym**. Powinieneś(-aś) być w stanie osiągnąć wynik conajmniej `0.95` accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.033333\ttrain: 1.000 test: 0.622\n",
      "Gamma: 0.000001\ttrain: 0.911 test: 0.951\n",
      "Gamma: 0.000010\ttrain: 0.915 test: 0.951\n",
      "Gamma: 0.000100\ttrain: 0.941 test: 0.965\n",
      "Gamma: 0.001000\ttrain: 0.977 test: 0.923\n",
      "Gamma: 0.010000\ttrain: 1.000 test: 0.629\n",
      "Gamma: 0.100000\ttrain: 1.000 test: 0.622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "auto_gamma = 1 / X_train.shape[1]\n",
    "scale_gamma = 1 / (X_train.shape[1] * X_train.var())\n",
    "\n",
    "best_test_acc = 0\n",
    "\n",
    "for g in [auto_gamma, scale_gamma, 0.00001, 0.0001, 0.001, 0.01, 0.1]:\n",
    "\n",
    "    svm = SVC(gamma=g)\n",
    "\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = svm.score(X_train, y_train)\n",
    "    \n",
    "    print(f\"Gamma: {g:0.6f}\", end='\\t')\n",
    "    print(f\"train: {train_score:0.3f}\", end=' ')\n",
    "    \n",
    "    test_score = svm.score(X_test, y_test)\n",
    "    \n",
    "    if test_score > best_test_acc:\n",
    "        best_test_acc = test_score\n",
    "        best_gamma = g\n",
    "    \n",
    "    print(f\"test: {test_score:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "best_gamma = best_gamma # ???\n",
    "\n",
    "svm = SVC(gamma=best_gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "test_acc = svm.score(X_test, y_test)\n",
    "\n",
    "assert test_acc >= 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem.\n",
    "\n",
    "**W poprzednim zadaniu zakładaliśmy, że podział na zbiór trenujący/testujący jest nam podany z góry, ale co jeśli go nie mamy?**\n",
    "\n",
    "Możemy oczywiście sami arbitralnie wybrać część datasetu i uznać ją za nasz zbiór testowy, ale to mogą się z tym wiązać dodatkowe problemy: co jeśli wybrany przez nas fragment jest akurat różny od reszty datasetu, lub odwrotnie?\n",
    "\n",
    "**Rozwiązanie:** Walidacja Krzyżowa.\n",
    "\n",
    "1. Podziel dataset na zadaną przez parametr `k` liczbę (prawie) równych grup.\n",
    "2. Dla każdego podziału, zwróć jedną z tych części jako zbiór testowy, a sumę reszty jako zbiów treningowy.\n",
    "3. Po nauczeniu łącznie `k` modeli, uśrednij ich wyniki na zbiorach testowych i zwróć jako ostateczny wynik.\n",
    "\n",
    "## Zadanie 2.\n",
    "\n",
    "Państwa zadaniem jest zaimplementowanie walidacji krzyżowej, czyli funkcji, która dla podanego datasetu w postaci macierzy danych `X` i wektora etykiet `y` zwróci listę `k` krotek: \n",
    "  \n",
    "  `(treningowe_dane, treningowe_etykiety, testowe_dane, testowe_etykiety)`\n",
    "  \n",
    "podziałów dokonanych przez walidacje krzyżową. Następnie należy użyć modelu z poprzedniego zadania dla policzenia dokładności na zbiorze testowym dla walidacji krzyżowej.\n",
    "\n",
    "Proszę **nie** korzystać z gotowych rozwiązań dostępnych w pakiecie sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def cross_validation(X: np.ndarray, y: np.ndarray, k: int) -> List[Tuple[np.ndarray, np.ndarray, \n",
    "                                                                         np.ndarray, np.ndarray]]:\n",
    "    \n",
    "    splits = []\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    split_size = N // k\n",
    "    \n",
    "    all_ids = set(range(N))\n",
    "    \n",
    "    for i, start_id in enumerate(range(0, N, split_size)):\n",
    "        if (i + 1) < k:\n",
    "            test_ids = set(range(start_id, start_id + split_size))\n",
    "        elif (i + 1) == k:\n",
    "            test_ids = set(range(start_id, N))\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        train_ids = list(all_ids - test_ids)\n",
    "        test_ids = list(test_ids)\n",
    "        \n",
    "        X_tr = X[train_ids]\n",
    "        y_tr = y[train_ids]\n",
    "        \n",
    "        X_te = X[test_ids]\n",
    "        y_te = y[test_ids]\n",
    "        \n",
    "        splits.append((X_tr, y_tr, X_te, y_te))\n",
    "    \n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cv(cross_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_data(split=False)\n",
    "\n",
    "# your code here\n",
    "\n",
    "accs = []\n",
    "\n",
    "splits = cross_validation(X, y, k=3)\n",
    "\n",
    "for X_train, y_train, X_test, y_test in splits:\n",
    "    \n",
    "    svm = SVC(gamma=0.01)\n",
    "    svm.fit(X_train, y_train)\n",
    "    test_acc = svm.score(X_test, y_test)\n",
    "    \n",
    "    accs.append(test_acc)\n",
    "    \n",
    "cv_accuracy = np.mean(accs) # ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to checker\n",
    "\n",
    "def test_cv(cv_func):\n",
    "    \n",
    "    X, y = get_data(split=False)\n",
    "    k = 5\n",
    "    \n",
    "    splits = cv_func(X=X, y=y, k=k)\n",
    "    \n",
    "    assert len(splits) == k, \"Wrong number of splits returned!\"\n",
    "    \n",
    "    for split in splits:\n",
    "        assert len(split) == 4, f\"Wrong tuple length for a single split, expected 4, got: {len(split)}\"\n",
    "        assert isinstance(split[0], np.ndarray), \"Wrong type returned!\"\n",
    "        assert isinstance(split[1], np.ndarray), \"Wrong type returned!\"\n",
    "        assert isinstance(split[2], np.ndarray), \"Wrong type returned!\"\n",
    "        assert isinstance(split[3], np.ndarray), \"Wrong type returned!\"\n",
    "        \n",
    "        assert len(split[0]) == len(split[1]), f\"Train split shape mismatch: {len(split[0])} and {len(split[1])}\"\n",
    "        assert len(split[2]) == len(split[3]), f\"Test split shape mismatch: {len(split[0])} and {len(split[1])}\"\n",
    "        \n",
    "    assert sum([split[2].shape[0] for split in splits]) == X.shape[0], \\\n",
    "        \"Sum of all split lengths is mismatched with whole dataset, did you use whole dataset for splitting?\"\n",
    "                                                                                                     \n",
    "                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3\n",
    "\n",
    "Mając już lepszą metode walidacji naszego rozwiązania Państwa zadaniem jest znalezienia najlepszego zestawu hiperparametrów dla modelu z poprzednich zadań, lecz tym razem będziemy szukać również parametru `C`. Parametru C zaleca się szukać w przedziale $(0, + \\infty)$ również w skali logarytmicznej.\n",
    "\n",
    "W zadaniu należy oczywiście skorzystać z zaimplementowanej przez Państwa walidacji krzyżowej. Ponieważ dla dwóch parametrów `C` oraz `gamma` możliwych kombinacji do przetestowania robi są dość sporo dla przetestowania dużych zakresów zalecane są również inne metody przeszukiwania, takie jak:\n",
    "\n",
    "* przeszukiwanie po kolei z jednym z parametów ustalonym na stałą.\n",
    "* przeszukiwanie losowe obu parametrów\n",
    "\n",
    "Oczywiście jeśli zasoby pozlową można szukać tzw. \"grid searchem\".\n",
    "\n",
    "Powinno udać się Państwu wyciągnąć przynamniej `0.94` accuracy na walidacji krzyżowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000.0, 5.856208850389724e-07)\n",
      "0.9455109559821602\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = get_data(split=False)\n",
    "\n",
    "auto_gamma = 1 / X_train.shape[1]\n",
    "scale_gamma = 1 / (X_train.shape[1] * X_train.var())\n",
    "\n",
    "results = {}\n",
    "\n",
    "for c in np.logspace(-3, 3, 7):\n",
    "    for g in [auto_gamma, scale_gamma, 0.00001, 0.0001, 0.001, 0.01, 0.1]:\n",
    "\n",
    "        accs = []\n",
    "\n",
    "        splits = cross_validation(X, y, k=3)\n",
    "\n",
    "        for X_train, y_train, X_test, y_test in splits:\n",
    "\n",
    "            svm = SVC(C=c, gamma=g)\n",
    "            svm.fit(X_train, y_train)\n",
    "            test_acc = svm.score(X_test, y_test)\n",
    "\n",
    "            accs.append(test_acc)\n",
    "\n",
    "        cv_accuracy = np.mean(accs) \n",
    "\n",
    "        results[(c, g)] = cv_accuracy\n",
    "        \n",
    "best_params, best_score = sorted(results.items(), key=lambda x: x[1], reverse=True)[0]\n",
    "print(best_params)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000000.0, 5.011872336272725e-08)\n",
      "0.9490198251105756\n"
     ]
    }
   ],
   "source": [
    "# random search\n",
    "\n",
    "X, y = get_data(split=False)\n",
    "\n",
    "results = {}\n",
    "\n",
    "max_iter = 50\n",
    "\n",
    "for i in range(max_iter):\n",
    "    \n",
    "    c = np.random.choice(np.logspace(-10, 10, 21))\n",
    "    g = np.random.choice(np.logspace(-10, -1, 11))\n",
    "\n",
    "    accs = []\n",
    "\n",
    "    splits = cross_validation(X, y, k=3)\n",
    "\n",
    "    for X_train, y_train, X_test, y_test in splits:\n",
    "\n",
    "        svm = SVC(C=c, gamma=g)\n",
    "        svm.fit(X_train, y_train)\n",
    "        test_acc = svm.score(X_test, y_test)\n",
    "\n",
    "        accs.append(test_acc)\n",
    "\n",
    "    cv_accuracy = np.mean(accs) \n",
    "\n",
    "    results[(c, g)] = cv_accuracy\n",
    "    \n",
    "best_params, best_score = sorted(results.items(), key=lambda x: x[1], reverse=True)[0]\n",
    "print(best_params)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0 3.981071705534969e-07\n",
      "0.9476439790575916\n"
     ]
    }
   ],
   "source": [
    "# one-by-one search\n",
    "\n",
    "X, y = get_data(split=False)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "auto_gamma = 1 / X_train.shape[1]\n",
    "scale_gamma = 1 / (X_train.shape[1] * X_train.var())\n",
    "\n",
    "\n",
    "best_acc = 0.\n",
    "    \n",
    "for c in np.logspace(-10, 10, 21):\n",
    "    \n",
    "    svm = SVC(C=c, gamma='scale')\n",
    "\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    acc = svm.score(X_test, y_test)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_c = c\n",
    "        best_acc = acc\n",
    "\n",
    "best_acc = 0.\n",
    "    \n",
    "for g in np.logspace(-10, -1, 11):\n",
    "    \n",
    "    svm = SVC(C=best_c, gamma=g)\n",
    "\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    acc = svm.score(X_test, y_test)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_gamma = g\n",
    "        best_acc = acc\n",
    "\n",
    "print(best_c, best_gamma)\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4.\n",
    "\n",
    "Załóżmy, że naszym problmem jest zdecydowanie, która rodzina modeli *SVM* najlepiej radzi sobei z naszym datasetem. Przez rodzinę rozumiemy tutaj modele SVM z różną *funkcją bazwoą* (zwaną często *funkcją jądra*). W pakiecie mamy dostępne kilka możliwości, włącznie z podawaniem swoich własnych, ale w tym zadaniu skupimy się na czterach dostępnych od ręki: `linear`, `poly`, `rbf`, `sigmoid`.\n",
    "\n",
    "Wiemy jak znaleźć najlepszy zestaw parametrów dla danej rodziny modeli, zrobiliśmy to do tej pory dla domyślnej funkcji bazowej czyli `rbf`. Jak jednak mamy \"uczciwie\" porównać wyniki modeli pomiędzy sobą? Do tej pory patrzyliśmy na wyniki modelu dla datasetu testowego i to na podstawie tego wyniku wybieraliśmy najlepsze hiperparametry. Jakie mogą być z tym problemy? Overfitting?\n",
    "\n",
    "Rozwiązanie: jeszcze jedna walidacja krzyżowa!\n",
    "\n",
    "1. Pierwsza walidacja krzyżowna podzieli nam nasz zbiór na treningowy i testowy. Te testowe zbiory będą naszymi ostatecznymi zbiorami testowymi, na których nie będziemy w żaden sposób się uczyć czy szukać hiperparametrów. \n",
    "2. Następnie nasz zbiór treningowy podzielimy ponownie walidacją krzyżową na dwie części: faktyczny treningowy i walidacyjny. Tych dwóch podziałów będziemy używać jak poprzednio do uczenia modelu i testowania hiperparametrów.\n",
    "3. Po znalezieniu najlepszego zestawu hiperparametrów nauczymy ostatecznie nasz model na sumie zbiorów treningowego i walidacyjnego i sprawdzimy jego dokładność na ostatecznym zbiorze testowym.\n",
    "\n",
    "\n",
    "**Uwaga**: paramter `C` używany jest dla każdej możliwej funkcji bazowej. Proszę sprawdzić jakie parametry są używane dla jakch funkcji jądra. \n",
    "**Hint**: parametry, które mogą państwa interesować to oczywiście `kernel`, oraz `C`, `degree`, `gamma`, `coef0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: linear 1/3\n",
      "Done: linear 2/3\n",
      "Done: linear 3/3\n",
      "Done: poly 1/3\n",
      "Done: poly 2/3\n",
      "Done: poly 3/3\n",
      "Done: rbf 1/3\n",
      "Done: rbf 2/3\n",
      "Done: rbf 3/3\n",
      "Done: sigmoid 1/3\n",
      "Done: sigmoid 2/3\n",
      "Done: sigmoid 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'linear': 0.9455109559821602,\n",
       " 'poly': 0.9472746244124952,\n",
       " 'rbf': 0.7535850485239665,\n",
       " 'sigmoid': 0.6269148729881714}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "X, y = get_data(split=False)\n",
    "\n",
    "cs = np.logspace(-3, 3, 7)\n",
    "degrees = [2, 3, 4]\n",
    "gammas = np.logspace(-4, -1, 5)\n",
    "coefs = [-1, 0, 1]\n",
    "\n",
    "k_cv = 3\n",
    "\n",
    "kernels_with_grids = {'linear': {'C': cs}, \n",
    "                      'poly': {'C': cs,\n",
    "                               'degree': degrees,\n",
    "                               'gamma': gammas,\n",
    "                               'coef0': coefs},\n",
    "                      'rbf': {'C': cs,\n",
    "                              'gamma': gammas},\n",
    "                      'sigmoid': {'C': cs,\n",
    "                               'gamma': gammas,\n",
    "                               'coef0': coefs}}\n",
    "\n",
    "def get_random_params(n_iter, params):\n",
    "    for i in range(n_iter):\n",
    "        yield {name: np.random.choice(param_space) for name, param_space in params.items()}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for kernel, grid in kernels_with_grids.items():\n",
    "    \n",
    "    kernal_res = []\n",
    "    kernel_accs = []\n",
    "    \n",
    "    splits = cross_validation(X, y, k=k_cv)\n",
    "    \n",
    "    for i, (X_train_valid, y_train_valid, X_test, y_test) in enumerate(splits):\n",
    "        \n",
    "        for param_set in get_random_params(n_iter=3, params=grid):\n",
    "            accs = []\n",
    "            \n",
    "            inner_split = cross_validation(X_train_valid, y_train_valid, k=k_cv)\n",
    "            \n",
    "            for X_train, y_train, X_valid, y_valid in inner_split:\n",
    "                \n",
    "                svm = SVC(kernel=kernel, **param_set)\n",
    "                svm.fit(X_train, y_train)\n",
    "                acc = svm.score(X_valid, y_valid)\n",
    "                \n",
    "                accs.append(acc)\n",
    "            \n",
    "            kernal_res.append((param_set, np.mean(accs)))\n",
    "            \n",
    "        best_set, best_acc = sorted(kernal_res, key=lambda x: x[1], reverse=True)[0]\n",
    "        \n",
    "        best_svm = SVC(kernel=kernel, **best_set)\n",
    "        best_svm.fit(X_train_valid, y_train_valid)\n",
    "        kernel_score = best_svm.score(X_test, y_test)\n",
    "        \n",
    "        kernel_accs.append(kernel_score)\n",
    "        print(f\"Done: {kernel} {i+1}/{len(splits)}\")\n",
    "        \n",
    "    results[kernel] = np.mean(kernel_accs)\n",
    "    \n",
    "    \n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
