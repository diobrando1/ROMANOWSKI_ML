{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ćwiczenia 6. Walidacja Krzyżowa\n",
    "\n",
    "## PyTorch na następne ćwiczenia.\n",
    "\n",
    "Proszę zainstalować pakiet [PyTorch](https://pytorch.org/) oraz torchvision na kolejne zajęcia. Jeśli używane, mając swoje środowisko aktywne użyć:\n",
    "\n",
    " * GPU: `conda install pytorch torchvision cudatoolkit=9.0 -c pytorch`\n",
    " * tylko CPU: `conda install pytorch torchvision cpuonly  -c pytorch`\n",
    "\n",
    "## Klasyfikacja\n",
    "\n",
    "Dzisiaj na zajęciach zajmiemy się problemem klasyfikacji. Podobnie do regresji liniowej jest to przykład uczenia nadzorowanego, ale zamiast przewidywać konkretną liczbę dla danej obserwacji, przewidujemy jego przynajeżność do jednej z *k* klas. Na tych zajęciach będziemy rozważać klasyfikacje binarną, czyli uczyć modele odpowiadające funkcji:\n",
    "\n",
    "$$ f(x) = y, \\quad y \\in \\{0,1\\} $$\n",
    "\n",
    "Poniżej ładowane są dane, do razu już podzielone na dwie części."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import get_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1.1 (0.5 pkt.)\n",
    "\n",
    "Używając modelu [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) z pakietu sklearn uzyskać 100% dokładność (mierzoną miarą [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html))na zbiorze treningowym. Państwa zadanie polega na dobraniu parametru `gamma`, dla ułatwienia proszę nie zmieniać pozostałych domyślnych parametrów. Zalecany przedział parametru `gamma` to wartości z przedziału [0, 1] w skali logarytmicznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "best_gamma = 0.1 # ???\n",
    "\n",
    "svm = SVC(gamma=best_gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "train_acc = svm.score(X_train, y_train)\n",
    "\n",
    "assert train_acc == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1.2 (0.5 pkt.)\n",
    "Używając tej samej rodziny modeli znajdź tym razem taką wartość `gamma`, która daje najlepszy wynik na zbiorze **testowym**. Powinieneś(-aś) być w stanie osiągnąć wynik co najmniej `0.95` accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "best_gamma = 0.0001 # ???\n",
    "\n",
    "svm = SVC(gamma=best_gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "test_acc = svm.score(X_test, y_test)\n",
    "\n",
    "assert test_acc >= 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem.\n",
    "\n",
    "**W poprzednim zadaniu zakładaliśmy, że podział na zbiór trenujący/testujący jest nam podany z góry, ale co jeśli go nie mamy?**\n",
    "\n",
    "Możemy oczywiście sami arbitralnie wybrać część datasetu i uznać ją za nasz zbiór testowy, ale to mogą się z tym wiązać dodatkowe problemy: co jeśli wybrany przez nas fragment jest akurat różny od reszty datasetu, lub odwrotnie?\n",
    "\n",
    "**Rozwiązanie:** Walidacja Krzyżowa.\n",
    "\n",
    "1. Podziel dataset na zadaną przez parametr `k` liczbę (prawie) równych grup.\n",
    "2. Dla każdego podziału, zwróć jedną z tych części jako zbiór testowy, a sumę reszty jako zbiór treningowy.\n",
    "3. Po nauczeniu łącznie `k` modeli, uśrednij ich wyniki na zbiorach testowych i zwróć jako ostateczny wynik.\n",
    "\n",
    "## Zadanie 2. (2 pkt.)\n",
    "\n",
    "Państwa zadaniem jest zaimplementowanie walidacji krzyżowej, czyli funkcji, która dla podanego datasetu w postaci macierzy danych `X` i wektora etykiet `y` zwróci listę `k` krotek: \n",
    "  \n",
    "  `(treningowe_dane, treningowe_etykiety, testowe_dane, testowe_etykiety)`\n",
    "  \n",
    "podziałów dokonanych przez walidację krzyżową. Następnie należy użyć modelu z poprzedniego zadania dla policzenia dokładności na zbiorze testowym dla walidacji krzyżowej.\n",
    "\n",
    "Proszę **nie** korzystać z gotowych rozwiązań dostępnych w pakiecie sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def cross_validation(X: np.ndarray, y: np.ndarray, k: int) -> List[Tuple[np.ndarray, np.ndarray, \n",
    "                                                                         np.ndarray, np.ndarray]]:\n",
    "    \n",
    "    # your code here\n",
    "    divisions, progress = [], X.shape[0] // k\n",
    "    \n",
    "    for i in range(k-1):\n",
    "        X1 = np.split(X, [i*progress, i*progress+progress, X.shape[0]])\n",
    "        y1 = np.split(y, [i*progress, i*progress+progress, y.shape[0]])\n",
    "        division = np.concatenate((X1[0], X1[2])), np.concatenate((y1[0], y1[2])), X1[1], y1[1]\n",
    "        divisions.append(division)\n",
    "        \n",
    "    i = k-1\n",
    "    X1 = np.split(X, [i*progress, X.shape[0]])\n",
    "    y1 = np.split(y, [i*progress, y.shape[0]])\n",
    "    division = np.concatenate((X1[0], X1[2])), np.concatenate((y1[0], y1[2])), X1[1], y1[1]\n",
    "    divisions.append(division)\n",
    "    \n",
    "    return divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checker import test_cv\n",
    "\n",
    "test_cv(cross_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941785063752277\n"
     ]
    }
   ],
   "source": [
    "X, y = get_data(split=False)\n",
    "\n",
    "# your code here\n",
    "k = 150\n",
    "sacc, divisions = 0, cross_validation(X, y, k)\n",
    "for division in divisions:\n",
    "    svm.fit(division[0], division[1])\n",
    "    sacc += svm.score(division[2], division[3])\n",
    "    \n",
    "cv_accuracy = sacc / k\n",
    "print(cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (1 pkt.)\n",
    "\n",
    "Mając już lepszą metodę walidacji naszego rozwiązania Państwa zadaniem jest znalezienia najlepszego zestawu hiperparametrów dla modelu z poprzednich zadań, lecz tym razem będziemy szukać również parametru `C`. Parametru C zaleca się szukać w przedziale $(0, + \\infty)$ również w skali logarytmicznej.\n",
    "\n",
    "W zadaniu należy oczywiście skorzystać z zaimplementowanej przez Państwa walidacji krzyżowej. Ponieważ dla dwóch parametrów `C` oraz `gamma` możliwych kombinacji do przetestowania robi są dość sporo dla przetestowania dużych zakresów zalecane są również inne metody przeszukiwania, takie jak:\n",
    "\n",
    "* przeszukiwanie po kolei z jednym z parametrów ustalonym na stałą.\n",
    "* przeszukiwanie losowe obu parametrów\n",
    "\n",
    "Oczywiście jeśli zasoby na to pozwalają można szukać tzw. \"grid searchem\".\n",
    "\n",
    "Powinno udać się Państwu wyciągnąć przynajmniej `0.94` accuracy na walidacji krzyżowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9525754481506693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = get_data(split=False)\n",
    "\n",
    "# your code here\n",
    "best_C, best_gamma = 10000, 0.00001\n",
    "k = 5\n",
    "\n",
    "# rowniez >=94%\n",
    "#best_C, best_gamma = 100, 0.0001\n",
    "#k = 150\n",
    "\n",
    "svm = SVC(C=best_C, gamma=best_gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "test_acc = svm.score(X_test, y_test)\n",
    "\n",
    "sacc, divisions = 0, cross_validation(X, y, k)\n",
    "for division in divisions:\n",
    "    svm.fit(division[0], division[1])\n",
    "    sacc += svm.score(division[2], division[3])\n",
    "    \n",
    "cv_accuracy = sacc / k\n",
    "print(cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4. (3 punkty)\n",
    "\n",
    "Załóżmy, że naszym problemem jest zdecydowanie, która rodzina modeli *SVM* najlepiej radzi sobei z naszym datasetem. Przez rodzinę rozumiemy tutaj modele SVM z różną *funkcją bazwoą* (zwaną często *funkcją jądra*). W pakiecie mamy dostępne kilka możliwości, włącznie z podawaniem swoich własnych, ale w tym zadaniu skupimy się na czterech dostępnych od ręki: `linear`, `poly`, `rbf`, `sigmoid`.\n",
    "\n",
    "Wiemy jak znaleźć najlepszy zestaw parametrów dla danej rodziny modeli, zrobiliśmy to do tej pory dla domyślnej funkcji bazowej czyli `rbf`. Jak jednak mamy \"uczciwie\" porównać wyniki modeli pomiędzy sobą? Do tej pory patrzyliśmy na wyniki modelu dla datasetu testowego i to na podstawie tego wyniku wybieraliśmy najlepsze hiperparametry. Jakie mogą być z tym problemy? Overfitting?\n",
    "\n",
    "Rozwiązanie: jeszcze jedna walidacja krzyżowa!\n",
    "\n",
    "1. Pierwsza walidacja krzyżowa podzieli nam nasz zbiór na treningowy i testowy. Te testowe zbiory będą naszymi ostatecznymi zbiorami testowymi, na których nie będziemy w żaden sposób się uczyć czy szukać hiperparametrów. \n",
    "2. Następnie nasz zbiór treningowy podzielimy ponownie walidacją krzyżową na dwie części: faktyczny treningowy i walidacyjny. Tych dwóch podziałów będziemy używać jak poprzednio do uczenia modelu i testowania hiperparametrów.\n",
    "3. Po znalezieniu najlepszego zestawu hiperparametrów nauczymy ostatecznie nasz model na sumie zbiorów treningowego i walidacyjnego i sprawdzimy jego dokładność na ostatecznym zbiorze testowym.\n",
    "\n",
    "\n",
    "**Uwaga**: parametr `C` używany jest dla każdej możliwej funkcji bazowej. Proszę sprawdzić jakie parametry są używane dla jakich funkcji jądra. \n",
    "**Hint**: parametry, które mogą państwa interesować to oczywiście `kernel`, oraz `C`, `degree`, `gamma`, `coef0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = get_data(split=False)\n",
    "\n",
    "# yout code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
