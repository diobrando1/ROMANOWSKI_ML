{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import torch\n",
    "\n",
    "from checker import check_07_logistic_reg, checker\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp do PyTorcha\n",
    "* PyTorch to biblioteka do uczenia maszynowego, w szczególności głębokiego.\n",
    "\n",
    "**Interfejs** jest bardzo podobny do numpy, z wyjątkiem pewnych zmian:\n",
    "* Zamiast `numpy.ndarray` naszym podstawowym obiektem będzie teraz `torch.Tensor`. Tensor, czyli uogólnienie macierzy do wyższych wymiarów.\n",
    "* Jeśli chcemy posumować macierz `A` po pierwszym wymiarze, w numpy zrobilibyśmy `A.sum(axis=0)`. W PyTorch zmienia się nazwa `A.sum(dim=0)`.\n",
    "* Zamiast `np.concatenate` jest `torch.cat`.\n",
    "* Zamiast `np.power` jest `torch.pow`.\n",
    "* I tym podobne.\n",
    "\n",
    "Przejście z `numpy.ndarray` do `torch.Tensor` (i na odwrót) jest bardzo proste:\n",
    "* `A (numpy.ndarray) -> B (torch.Tensor)`: `B = torch.from_numpy(A)`\n",
    "* `B (torch.Tensor) -> A (numpy.ndarray)`: `A = B.numpy()`\n",
    "    \n",
    "Kluczowe różnice:\n",
    "* PyTorch **automatycznie liczy dla nas gradienty**. Nie musimy własnoręcznie liczyć na kartce wzoru na gradient a potem przepisywać go do programu.\n",
    "* PyTorch ma **wsparcie dla GPU**, co umożliwia szybkie obliczenia w sieciach neuronowych.\n",
    "\n",
    "Dobre materiały do nauki PyTorcha: [Deep Learning in 60 minutes](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html), [PyTorch Examples](https://github.com/pytorch/examples).\n",
    "\n",
    "Drobna uwaga - te tutoriale opisują abstrakcje takie jak `torch.nn.Module`, `torch.optim.SGD` czy `torch.utils.data`, którymi będziemy się zajmować od kolejnych zajęć. Na tych zajęciach spróbujemy zobaczyć, co PyTorch robi \"pod spodem\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatyczne różniczkowanie w PyTorchu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(loss, X, parameters, y=None, lr=1e-6, num_steps=int(1e4)):\n",
    "    for idx in range(num_steps):\n",
    "        # Informujemy PyTorcha, że chcemy dostać gradient po naszych parametrach\n",
    "        parameters.requires_grad = True\n",
    "        \n",
    "        # Liczymy wartość funkcji kosztu.\n",
    "        loss_val = loss(X, parameters, y)\n",
    "        \n",
    "        # Każemy PyTorchowi policzyć gradient\n",
    "        loss_val.backward()\n",
    "        \n",
    "        # Wyciągamy gradient po parametrach\n",
    "        gradient = parameters.grad\n",
    "\n",
    "        # Wykonujemy krok metody spadku gradientu\n",
    "        with torch.no_grad():\n",
    "            parameters = parameters - lr * gradient\n",
    "    \n",
    "    # Zwracamy najlepsze parametry\n",
    "    return parameters\n",
    "\n",
    "# Dziwna funkcja, której minimum będziemy chcieli znaleźć.\n",
    "def complex_fn(a, x, _=None):\n",
    "    y = a[0] / a[1] * torch.cos(a[0] * x ** 2 + a[1] * x - a[2])\n",
    "    z = torch.exp(-x) / (y + 3)\n",
    "    return -(z + y) + torch.exp(-x - 0.8)\n",
    "\n",
    "a = torch.tensor([3, 2, 1])\n",
    "x = torch.tensor(-4.)\n",
    "result = gradient_descent(complex_fn, a, x, lr=2.5e-2, num_steps=int(1e4))\n",
    "\n",
    "utils.plot_torch_fn(complex_fn, a, x, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing datasets\n",
    "torch.manual_seed(5)\n",
    "\n",
    "# Regression dataset\n",
    "boston = datasets.load_boston()\n",
    "boston_X = torch.tensor(boston.data, dtype=torch.float32)\n",
    "boston_y = torch.tensor(boston.target, dtype=torch.float32)\n",
    "boston_w = torch.randn(boston_X.shape[1], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Log Likelihood dataset\n",
    "dataset_1d = torch.randn([1000], dtype=torch.float32)\n",
    "theta = torch.randn([2], dtype=torch.float32, requires_grad=True) + 5\n",
    "\n",
    "# Multidimensional datasets\n",
    "dataset_5d = torch.randn([1000, 5], dtype=torch.float32)\n",
    "param_5d = torch.randn(5, requires_grad=True)\n",
    "\n",
    "dataset_20d = torch.randn([325, 20], dtype=torch.float32)\n",
    "param_20d = torch.randn(20, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 (2 pkt.)\n",
    "\n",
    "Zaimplementuj w PyTorchu funkcje kosztu, które minimalizowaliśmy na wcześniejszych ćwiczeniach. Czyli konkretnie:\n",
    "* `mean_squared_error` (lab 02)\n",
    "* `mean_error` (lab 02)\n",
    "* `max_error` (lab 02)\n",
    "* `negative_log_likelihood` (lab 03)\n",
    "* `linear_regression_loss` (lab 05)\n",
    "* `regularized_regression_loss` (lab 05)\n",
    "\n",
    "Proszę te funkcje przekleić (ze swoich rozwiązań czy też oficjalnych) i przerobić tak, żeby przyjmowały `torch.Tensor` zamiast `np.ndarray` oraz zwracały `torch.Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@checker\n",
    "def mean_squared_error(X: torch.Tensor, theta: torch.Tensor, y=None) -> torch.Tensor:\n",
    "    squared_distances = torch.sum((X - theta).pow(2), dim=-1)\n",
    "    return torch.mean(squared_distances)\n",
    "\n",
    "mean_squared_error(dataset_20d, param_20d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@checker\n",
    "def mean_error(X: torch.Tensor, theta: torch.Tensor, y=None) -> torch.Tensor:\n",
    "    return torch.mean(torch.norm(X - theta, dim=-1))\n",
    "\n",
    "mean_error(dataset_5d, param_5d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@checker\n",
    "def max_error(X: torch.Tensor, theta: torch.Tensor, y=None) -> torch.Tensor:\n",
    "    norms = torch.norm(X - theta, dim=-1)\n",
    "    return torch.max(norms)\n",
    "\n",
    "max_error(dataset_20d, param_20d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@checker\n",
    "def negative_log_likelihood(X: torch.Tensor, theta: torch.Tensor, y=None) -> torch.Tensor:\n",
    "    mu, sigma = theta\n",
    "    N = X.shape[0]\n",
    "    log_like = - N / 2 * np.log(2 * np.pi) - N / 2 * np.log(sigma.detach().numpy() ** 2)\n",
    "    log_like -= 1 / (2 * sigma ** 2) * torch.sum((mu - X) ** 2)\n",
    "    return -log_like\n",
    "\n",
    "negative_log_likelihood(dataset_1d, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@checker\n",
    "def linear_regression_loss(X: torch.Tensor, w: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.sum(((w.reshape(-1,1).T @ X.T) - y).pow(2)) / X.shape[0]\n",
    "\n",
    "linear_regression_loss(boston_X, boston_w, boston_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@checker\n",
    "def regularized_regression_loss(X: torch.Tensor, w: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    alpha = 0.2\n",
    "    return torch.sum(((w.reshape(-1,1).T @ X.T) - y).pow(2)) / X.shape[0] + alpha * torch.norm(w)**2\n",
    "\n",
    "regularized_regression_loss(boston_X, boston_w, boston_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Część 1: Klasyfikacja liniowa\n",
    "## Modele probabilistyczne i decyzyjne\n",
    "Przyjmujemy, że mamy zadanie klasyfikacji binarnej. Na poprzednich zajęciach używaliśmy metody do klasyfikacji - Support Vector Machine, która dla zadanego przykładu podawała nam po prostu $y$. SVM nie jest jednak w stanie powiedzieć nam jak bardzo pewny jest swojej decyzji. \n",
    "\n",
    "* **Modele decyzyjne** - są w stanie odpowiedzieć nam, jaki jest najbardziej prawdopodobna etykieta $y$ dla przykładu $x$, ale nie dają rozkładu prawdopodobieństwa. Przykładem takiego modelu jest SVM, z którego korzystaliśmy na poprzednich zajęciach.\n",
    "* **Modele probabilistyczne** - zadają nam rozkład na etykietach $p(y \\mid x)$, dzięki czemu dostajemy więcej informacji.\n",
    "\n",
    "**Pytanie:** Dlaczego może nas interesować cały rozkład prawdopodobieństwa zamiast najbardziej prawdopodobnej odpowiedzi?\n",
    "\n",
    "## Probabilistyczna klasyfikacja binarna\n",
    "Chcielibyśmy stworzyć model, który otrzymując na wejściu $x$ będzie w stanie nam powiedzieć, jakie jest prawdopodobieństwo, że $y = 0$. Tzn, jeśli nasz model to funkcja $g(x)$, to nasza funkcja ma zadawać rozkład prawdopodobieństwa:\n",
    "\n",
    "$$g(x) = \\hat{p}(y = 1 \\mid x)$$\n",
    "\n",
    "Z tego możemy łatwo wyciągnąć prawdopodobieństwo, że zadany przykład ma etykietę $0$, tzn:\n",
    "$$ \\hat{p}(y = 0 \\mid x) = 1 - \\hat{p}(y = 1 \\mid x) = 1 - g(x) $$\n",
    "\n",
    "\n",
    "**Pytanie:** Kiedy będziemy mieli model zadający nam rozkład $\\hat{p}(y \\mid x)$, jak odpowiedzieć na pytanie \"jaka jest etykieta zadanego przykładu\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna\n",
    "\n",
    "**Problem:** Jak uzyskać probabilistyczny model klasyfikacyjny? Moglibyśmy użyć naszego modelu liniowego o postaci $f(x) = w^Tx + b$, ale ten model ma wadę, że może przyjmować dowolne wartości ze zbioru liczb rzeczywistych, tzn. $f(x) \\in \\mathbb{R}$, natomiast z definicji prawdopodobieństwo $p(y=1) \\in [0, 1]$.\n",
    "\n",
    "*Uwaga: Wcześniej nasz model liniowy był postaci $f(x) = w^Tx$, teraz dodaliśmy jeszcze tzw. bias $b \\in \\mathbb{R}$, który pozwala nam reprezentować przekształcenia afiniczne a nie tylko liniowe.* \n",
    "\n",
    "**Rozwiązanie:** Potrzebujemy więc funkcji, która \"spłaszczy\" nam przedział $\\mathbb{R}$ do $[0, 1]$. Można by taką funkcję znaleźć na wiele sposobów, ale z powodów technicznych najczęściej korzysta się z sigmoidy, tzn.:\n",
    "$$ \\sigma(x) = \\frac{1}{1 + \\exp(-x)} $$\n",
    "\n",
    "**Wykres funkcji sigmoid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"sigma(x)\")\n",
    "plt.plot(np.linspace(-6, 6), 1 / (1 + np.exp(-np.linspace(-6, 6))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatecznie nasz model wygląda tak:\n",
    "$$\n",
    "    \\hat{p}(y = 1 \\mid x) = \\sigma(w^Tx + b)\n",
    "$$\n",
    "\n",
    "Mamy więc model, który jest w stanie dać nam rozkład prawdopodobieństwa etykiety pod warunkiem $\\hat{p}(y \\mid x)$. Nasz zbiór treningowy zawiera też próbki z prawdziwego rozkładu prawdopodobieństwa: $p(y_i \\mid x_i)$.\n",
    "\n",
    "Jako funkcję kosztu wybieramy sobie więc \"różnicę\" pomiędzy prawdziwym rozkładem, a rozkładem zadanym przez nasz model. W tym wypadku sprawdza się **entropia krzyżowa** (cross-entropy), zadana wzorem:\n",
    "\n",
    "\n",
    "\\begin{split}\n",
    "      \\mathcal{H}(p(y \\mid x_i), \\hat{p}(y \\mid x_i)) &= -\\sum_{k \\in \\{0, 1\\}} p(y=k \\mid x_i) \\ln \\hat{p}(y=k \\mid x_i) \\\\\n",
    "      &= -p(y = 0 \\mid x_i) \\ln \\hat{p}(y = 0 \\mid x_i) - p(y=1 \\mid x_i) \\ln \\hat{p}(y=1 \\mid x_i) \\\\\n",
    "      &= -(1 - p(y = 1 \\mid x_i)) \\ln (1 - \\hat{p}(y = 1 \\mid x_i)) - p(y=1 \\mid x_i) \\ln \\hat{p}(y=1 \\mid x_i) \\\\\n",
    "      &= - (1 - y_i) \\ln (1 - \\hat{y}) - y_i \\ln \\hat{y} ,\n",
    "\\end{split}\n",
    "gdzie podstawiliśmy sobie: $$\\hat{p}(y=1 \\mid x_i) = \\hat{y}, \\\\ p(y=1 \\mid x_i) = y_i$$\n",
    "\n",
    "Ustalmy teraz, że ostateczna funkcja kosztu naszego modelu to będzie średnia entropia krzyżowa dla zbioru danych:\n",
    "$$\n",
    "    \\mathcal{L}(X) = \\frac{1}{N} \\sum_{(x_i, y_i) \\in X}^N  \\mathcal{H}(p(y \\mid x_i), \\hat{p}(y \\mid x_i))\n",
    "$$\n",
    "\n",
    "\n",
    "Taki model możemy teraz optymalizować metodą spadku gradientu i wykorzystać do klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotujmy datasety i funkcje pomocnicze\n",
    "dataset_1d = utils.get_classification_dataset_1d()\n",
    "dataset_2d = utils.get_classification_dataset_2d()\n",
    "\n",
    "def calculate_accuracy(logistic_reg, X, y):\n",
    "    preds = logistic_reg.predict(X)\n",
    "    correct_n = (preds == y).float().sum().item()\n",
    "    return correct_n / len(y)\n",
    "\n",
    "def plot_dataset_1d(logistic_reg, dataset_1d):\n",
    "    plt.scatter(dataset_1d.data[:10], [0.5] * 10, c=\"purple\", label=\"0\")\n",
    "    plt.scatter(dataset_1d.data[10:], [0.5] * 10, c=\"yellow\", label=\"1\")\n",
    "    linspace = torch.linspace(-7.5, 15).view(-1, 1)\n",
    "    plt.plot(\n",
    "        linspace.numpy().ravel(),\n",
    "        logistic_reg.predict_proba(linspace).detach().numpy(),\n",
    "        label=\"p(y=1 | x)\"\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_dataset_2d(logistic_reg, dataset_2d):\n",
    "    plt.scatter(dataset_2d.data[:50, 0], dataset_2d.data[:50, 1], c=\"purple\", label=\"0\")\n",
    "    plt.scatter(dataset_2d.data[50:, 0], dataset_2d.data[50:, 1], c=\"yellow\", label=\"1\")\n",
    "\n",
    "    linspace_x = torch.linspace(-4, 7)\n",
    "    linspace_y = (-logistic_reg.bias - logistic_reg.weight[0] * linspace_x) / logistic_reg.weight[1]\n",
    "\n",
    "    linspace_y = linspace_y.detach().numpy()\n",
    "    plt.plot(linspace_x.detach().numpy(), linspace_y, label=\"Granica decyzyjna\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 (2 pkt.)\n",
    "\n",
    "Zaimplementuj w PyTorchu regresję logistyczną. W tym celu trzeba napisać następujące funkcje:\n",
    "1. Funkcję kosztu modelu regresji logistycznej `loss(X, y)`, według następujących kroków:\n",
    "    * Policz model liniowy $z = w^Tx + b$\n",
    "    * Na wektorze $z$ zaimplementuj funkcję $\\hat{y} = \\sigma(z) = \\frac{1}{1 + \\exp(-z)}$.\n",
    "    * Policz entropię krzyżową pomiędzy predykcjami $\\hat{y}$ a etykietami $y$ zadaną przez:\n",
    "    $\\frac{1}{N} \\sum_i - (1 - y_i) \\ln (1 - \\hat{y}_i) - y_i \\ln \\hat{y}_i$\n",
    "2. Funkcję `predict_proba(X)` zwracającą dla każdego $x_i \\in X$ zadane przez nasz model prawdopodobieństwo $\\hat{p}(y = 1 \\mid x_i)$. \n",
    "3. Funkcję `predict(X)` zwracającą dla każdego $x_i \\in X$ przewidywaną etykietę (tzn. $0$ albo $1$). Zwracana etykieta powinna być typu `float`.\n",
    "\n",
    "**UWAGA** Nie można korzystać z funkcji PyTorcha do liczenia entropii krzyżowej (np. `torch.nn.BCELoss`) ani sigmoidy (np.`torch.nn.functional.Sigmoid`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, input_dim):\n",
    "        self.weight = None \n",
    "        self.bias = None \n",
    "        self.input_dim = input_dim\n",
    "    \n",
    "    def fit(self, X, y, lr=1e-6, num_steps=int(1e4)):\n",
    "        self.weight = torch.randn(self.input_dim, requires_grad=True)\n",
    "        self.bias = torch.randn((), requires_grad=True)\n",
    "        for idx in range(num_steps):\n",
    "            self.weight.requires_grad = True\n",
    "            self.bias.requires_grad = True\n",
    "            \n",
    "            loss_val = self.loss(X, y)\n",
    "            loss_val.backward()\n",
    "            \n",
    "            w_grad = self.weight.grad\n",
    "            b_grad = self.bias.grad\n",
    "            with torch.no_grad():\n",
    "                self.weight = self.weight - lr * w_grad\n",
    "                self.bias = self.bias - lr * b_grad\n",
    "        \n",
    "    def predict_proba(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        # W trakcie predykcji nie potrzebujemy liczyć gradientów\n",
    "        ps = None\n",
    "        with torch.no_grad():\n",
    "            z = (self.weight.view(-1,1).T @ X.T).squeeze() + self.bias\n",
    "            ps = (1 / (1 + torch.exp(-z))).squeeze()\n",
    "        return ps\n",
    "            \n",
    "    def predict(self, X: torch.Tensor) -> torch.FloatTensor:\n",
    "        ps = self.predict_proba(X)\n",
    "        return torch.FloatTensor([1.0 if ps[i] > 0.5 else 0.0 for i in range(ps.shape[0])])\n",
    "            \n",
    "    def loss(self, X: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        z = (self.weight.view(-1,1).T @ X.T).squeeze() + self.bias\n",
    "        y_m = (1 / (1 + torch.exp(-z)))\n",
    "        s = -(1-y) * torch.log(1-y_m) - y*torch.log(y_m)\n",
    "        return torch.mean(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_07_logistic_reg(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(1)\n",
    "logistic_reg.fit(dataset_1d.data, dataset_1d.target, lr=1e-3, num_steps=int(2e4))\n",
    "acc = calculate_accuracy(logistic_reg, dataset_1d.data, dataset_1d.target)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "plot_dataset_1d(logistic_reg, dataset_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(2)\n",
    "logistic_reg.fit(dataset_2d.data, dataset_2d.target, lr=1e-2, num_steps=int(2e4))\n",
    "acc = calculate_accuracy(logistic_reg, dataset_2d.data, dataset_2d.target)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "plot_dataset_2d(logistic_reg, dataset_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Część 2: Reguła łańcuchowa i automatyczne różniczkowanie\n",
    "\n",
    "Przypomnijmy sobie regułę łańcuchową liczenia pochodnych. Jeśli mamy:\n",
    "$$ L(x) = g(f(x)), $$ \n",
    "to wtedy:\n",
    "\n",
    "$$ \\frac{dL(x)}{dx} = \\frac{dL(x)}{df(x)}\\frac{df(x)}{dx} $$\n",
    "\n",
    "W kontekście automatycznego różniczkowania w PyTorchu kluczowa jest tu właściwość, że do policzenia gradientu nie musimy nic wiedzieć o $g(x)$ o ile tylko znamy $\\frac{dL(x)}{df(x)}$. **Każdy moduł wie, jak policzyć swój gradient i dzięki temu można łańcuchowo liczyć pochodne skomplikowanych funkcji.**\n",
    "\n",
    "\n",
    "W PyTorchu każda funkcja, której używamy, ma zaimplementowane dwa podmoduły:\n",
    "* **Forward** - na podstawie podanego $x$ potrafi obliczyć $f(x)$. \n",
    "* **Backward** - na podstawie podanego $\\frac{dL(x)}{df(x)}$ potrafi policzyć $\\frac{dL(x)}{dx}$.\n",
    "\n",
    "Więcej o automatycznym różniczkowaniu można przeczytać w [dokumentacji PyTorcha](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotujmy sobie dane do testów\n",
    "input = torch.randn(30, 20, dtype=torch.double, requires_grad=True) * 3\n",
    "a = torch.randn(20, 30, requires_grad=True).double() * 2 - 5\n",
    "b = torch.randn(20, 30, requires_grad=True).double() + 6\n",
    "\n",
    "\n",
    "preds = torch.rand(30, requires_grad=True).double()\n",
    "labels_dist = torch.distributions.Bernoulli(probs=0.7)\n",
    "labels = labels_dist.sample([30]).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład: różniczkowanie mnożenia\n",
    "Chcemy zaimplementować od nowa w PyTorchu fukcję $f(a, b) = a \\cdot b$, która potrafi policzyć swoje pochodne.\n",
    "\n",
    "W efekcie implementujemy obiekt typu `torch.autograd.Function` z metodami:\n",
    "* **Forward** \n",
    "    1. Dostaje na wejściu `a` oraz `b`\n",
    "    1. Zapamiętuje `a` oraz `b`, które przydadzą się później przy liczeniu pochodnej\n",
    "    2. Zwraca `a * b`\n",
    "* **Backward**\n",
    "    1. Dostaje na wejściu `grad_output` reprezentujące wartość $\\frac{dL(x)}{df(a, b)}$.\n",
    "    2. Wyjmuje z pamięci `a` oraz `b`.\n",
    "    3. Liczy swoją pochodną po a: $\\frac{df(a, b)}{da} = \\frac{da}{da} \\cdot b + a \\cdot \\frac{da}{db} = 1\\cdot b + a\\cdot 0 = b$\n",
    "    4. Liczy swoją pochodną po b: $\\frac{df(a, b)}{db} = \\frac{da}{db} \\cdot b + a \\cdot \\frac{db}{db} = 0\\cdot b + a\\cdot 1 = a$\n",
    "    5. Zwraca pochodne $\\frac{dL(x)}{df(a, b)} \\frac{df(a, b)}{da}$ oraz $\\frac{dL(x)}{df(a, b)} \\frac{df(a, b)}{db}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProduct(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(self, a, b):\n",
    "        self.save_for_backward(a, b)\n",
    "        return a * b\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        # Wyjmujemy z pamięci a oraz b\n",
    "        a, b = self.saved_tensors\n",
    "        # Liczymy pochodną po a\n",
    "        a_grad = b\n",
    "        # Liczymy pochodną po b\n",
    "        b_grad = a\n",
    "        \n",
    "        # Zwracamy \"łańcuchowe\" pochodne\n",
    "        return grad_output * a_grad, grad_output * b_grad\n",
    "    \n",
    "prod_fn = MyProduct.apply\n",
    "torch.autograd.gradcheck(prod_fn, (a, b), eps=1e-3, atol=1e-2, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (3 pkt.)\n",
    "Proszę zaimplementować backward pass w następujących funkcjach:\n",
    "* MyAdd(a, b): a + b\n",
    "* MyDiv(a, b): a / b\n",
    "* MySigmoid(input): tak jak w zadaniu 2\n",
    "* BCE(preds, labels): tak jak w zadaniu 2 (jako że nie liczymy tutaj pochodnej po etykietach, można zwrócić `grad_labels = None`)\n",
    "\n",
    "**Zdarza się, że funkcja do testowania gradientu `torch.autograd.gradcheck` będzie wyrzucała błędy przez niedokładności numeryczne. Proszę odświeżyć dane i spróbować jeszcze raz.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAdd(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, a, b):\n",
    "        self.save_for_backward(a, b)\n",
    "        return a + b\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        a, b = self.saved_tensors\n",
    "        df_da, df_db = 1, 1\n",
    "        return grad_output * df_da, grad_output * df_db\n",
    "\n",
    "add_fn = MyAdd.apply\n",
    "torch.autograd.gradcheck(add_fn, (a, b), eps=1e-3, atol=1e-2, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDiv(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, a, b):\n",
    "        self.save_for_backward(a, b)\n",
    "        return a / b\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        a, b = self.saved_tensors\n",
    "        df_da, df_db = 1/b, -a/(b*b)\n",
    "        return grad_output * df_da, grad_output * df_db\n",
    "\n",
    "div_fn = MyDiv.apply\n",
    "torch.autograd.gradcheck(div_fn, (a, b), eps=1e-3, atol=1e-2, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySigmoid(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, input_):\n",
    "        self.save_for_backward(input_)\n",
    "        return (1 / (1 + torch.exp(-input_)))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        input_, = self.saved_tensors\n",
    "        f = (1 / (1 + torch.exp(-input_)))\n",
    "        df_dinput = f * (1 - f)\n",
    "        return grad_output * df_dinput\n",
    "    \n",
    "\n",
    "sigmoid_fn = MySigmoid.apply\n",
    "torch.autograd.gradcheck(sigmoid_fn, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBinaryCrossEntropy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, preds, labels, bias=None):\n",
    "        self.save_for_backward(preds, labels)\n",
    "        return -(1-labels) * torch.log(1-preds) - labels*torch.log(preds)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):\n",
    "        preds, labels = self.saved_tensors\n",
    "        grad_labels = None\n",
    "        #df_dpreds = torch.log(1-labels) - torch.log(labels)\n",
    "        df_dpreds = -(1-labels) * (1/torch.log(1-preds)) * -preds - labels * (1/preds)\n",
    "        return grad_output * df_dpreds, fgrad_labels\n",
    "\n",
    "bce_fn = MyBinaryCrossEntropy.apply\n",
    "torch.autograd.gradcheck(bce_fn, (preds, labels), eps=1e-3, atol=1e-2, rtol=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotowujemy prosty dataset\n",
    "X = torch.cat([\n",
    "    torch.randn(10) * 3 + 2,\n",
    "    torch.randn(10) * 3 + 12\n",
    "])\n",
    "y = torch.cat([torch.zeros(10), torch.ones(10)])\n",
    "\n",
    "\n",
    "# Inicjalizujemy zmienne\n",
    "weight = torch.randn((), requires_grad=True)\n",
    "bias = torch.randn((), requires_grad=True)\n",
    "\n",
    "lr = 1e-1\n",
    "for idx in range(10000):\n",
    "    weight.requires_grad = True\n",
    "    bias.requires_grad = True\n",
    "    \n",
    "    # Liczymy funkcję kosztu za pomocą naszych modułów\n",
    "    logit = add_fn(prod_fn(weight, X), bias)\n",
    "    pred = sigmoid_fn(logit)\n",
    "    loss = bce_fn(pred, y)\n",
    "    \n",
    "    # Gradient przechodzi przez funkcję backward każdego modułu\n",
    "    loss.backward()\n",
    "    \n",
    "    # Wyciągamy gradienty\n",
    "    w_grad = weight.grad\n",
    "    b_grad = bias.grad\n",
    "    \n",
    "    # Wykonujemy krok metody spadku gradientu\n",
    "    with torch.no_grad():\n",
    "        weight = weight - lr * w_grad\n",
    "        bias = bias - lr * b_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, np.zeros_like(X) + 0.5, c=y.numpy())\n",
    "\n",
    "linspace = torch.linspace(-5, 15).view(-1, 1)\n",
    "with torch.no_grad():\n",
    "    plt.plot(\n",
    "        linspace.numpy().ravel(),\n",
    "        sigmoid_fn(add_fn(prod_fn(weight, linspace), bias)).detach().numpy(),\n",
    "        label=\"p(y=0 | x)\"\n",
    "    )\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dygresje\n",
    "* Istnieją inne frameworki do deep learningu poza PyTorchem. Szczególnie popularny jest teraz TensorFlow (często używany razem z Kerasem). Popularne w przeszłości, ale wciąż poniekąd istotne są: Theano, Caffe, MXNet. \n",
    "* Sigmoid staje się bardziej naturalny, kiedy myślimy o outputach z modelu liniowego jako o logarytmie szans (*log-odds* albo *logits*). [Więcej tutaj](https://en.wikipedia.org/wiki/Logistic_regression#Logistic_model). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
